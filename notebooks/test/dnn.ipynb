{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "preprocessed_data_path = './preprocessed_data/'\n",
    "pred_path = './result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_d, y_train_d, w_train_d, e_train_d, x_test_d, id_test_d = utils.load_preprocessed_pd_data(preprocessed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_d, '\\n',\n",
    "      y_train_d, '\\n',\n",
    "      w_train_d, '\\n',\n",
    "      e_train_d, '\\n',\n",
    "      x_test_d, '\\n',\n",
    "      id_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "learning_rate = 0.001\n",
    "n_unit = [48, 24, 12, 6, 3]\n",
    "keep_prob_ = 1.0\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "save_path = './checkpoints/'\n",
    "log_path = './log/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(x_train_d.shape)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_num = list(x_train_d.shape)[1]\n",
    "\n",
    "inputs = tf.placeholder(tf.float64, [None, feature_num], name='inputs')\n",
    "labels = tf.placeholder(tf.float64, None, name='labels')\n",
    "weights = tf.placeholder(tf.float64, None, name='loss_weights')\n",
    "is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "keep_prob = tf.placeholder(tf.float64, None, name='keep_prob')\n",
    "\n",
    "def fc_layer(x_tensor, num_outputs):\n",
    "\n",
    "    fc = tf.contrib.layers.fully_connected(x_tensor,\n",
    "                                           num_outputs,\n",
    "                                           activation_fn=tf.nn.sigmoid,\n",
    "                                           weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                                           # weights_initializer=tf.contrib.layers.xavier_initializer(dtype=tf.float64),\n",
    "                                           biases_initializer=tf.zeros_initializer())\n",
    "\n",
    "    fc_d = tf.nn.dropout(fc, keep_prob)\n",
    "\n",
    "    return fc_d\n",
    "\n",
    "fc1 = fc_layer(inputs, n_unit[0])\n",
    "fc2 = fc_layer(fc1, n_unit[1])\n",
    "fc3 = fc_layer(fc2, n_unit[2])\n",
    "fc4 = fc_layer(fc3, n_unit[3])\n",
    "fc5 = fc_layer(fc4, n_unit[4])\n",
    "logits = tf.contrib.layers.fully_connected(fc5,\n",
    "                                           1,\n",
    "                                           activation_fn=None,\n",
    "                                           weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                                           # weights_initializer=tf.contrib.layers.xavier_initializer(dtype=tf.float64),\n",
    "                                           biases_initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob = tf.squeeze(logits)\n",
    "\n",
    "weights = weights / tf.reduce_sum(weights)\n",
    "\n",
    "# cost = - tf.reduce_sum(weights * (labels * tf.log(prob) +\n",
    "#                         (tf.ones_like(labels, dtype=tf.float64) - labels) * tf.log(tf.ones_like(labels, dtype=tf.float64)-prob)))\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def era_k_fold_with_weight(x, y, w, e, n_valid, n_cv):\n",
    "\n",
    "    for i in range(n_cv):\n",
    "\n",
    "        era_idx = list(range(1, 21))\n",
    "        valid_group = np.random.choice(era_idx, n_valid, replace=False)\n",
    "\n",
    "        train_index = []\n",
    "        valid_index = []\n",
    "\n",
    "        for ii, ele in enumerate(e):\n",
    "\n",
    "            if ele in valid_group:\n",
    "                valid_index.append(ii)\n",
    "            else:\n",
    "                train_index.append(ii)\n",
    "\n",
    "        np.random.shuffle(train_index)\n",
    "        np.random.shuffle(valid_index)\n",
    "\n",
    "        # Training data\n",
    "        x_train = x[train_index]\n",
    "        y_train = y[train_index]\n",
    "        w_train = w[train_index]\n",
    "\n",
    "        # Validation data\n",
    "        x_valid = x[valid_index]\n",
    "        y_valid = y[valid_index]\n",
    "        w_valid = w[valid_index]\n",
    "\n",
    "        yield x_train, y_train, w_train, x_valid, y_valid, w_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, w, batch_num):\n",
    "\n",
    "    n_batches = len(x) // batch_num\n",
    "\n",
    "    for ii in range(0, n_batches * batch_num, batch_num):\n",
    "\n",
    "        if ii != n_batches * batch_num:\n",
    "            batch_x, batch_y, batch_w = x[ii: ii + batch_num], y[ii: ii + batch_num], w[ii: ii + batch_num]\n",
    "\n",
    "        else:\n",
    "            batch_x, batch_y, batch_w = x[ii:], y[ii:], w[ii:]\n",
    "\n",
    "        yield batch_x, batch_y, batch_w\n",
    "        \n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    cv_counter = 0\n",
    "\n",
    "    prob_total = []\n",
    "\n",
    "    for x_train, y_train, w_train, \\\n",
    "        x_valid, y_valid, w_valid in era_k_fold_with_weight(x_train_d,\n",
    "                                                            y_train_d,\n",
    "                                                            w_train_d,\n",
    "                                                            e_train_d,\n",
    "                                                            4, 20):\n",
    "\n",
    "        cv_counter += 1\n",
    "\n",
    "        print('======================================================================================================')\n",
    "        print('Training on the Cross Validation Set: {}'.format(cv_counter))\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        batch_counter = 0\n",
    "\n",
    "        for epoch_i in range(epochs):\n",
    "\n",
    "            for batch_i, (batch_x, batch_y, batch_w) in enumerate(get_batches(x=x_train,\n",
    "                                                                              y=y_train,\n",
    "                                                                              w=w_train,\n",
    "                                                                              batch_num = batch_size)):\n",
    "                \n",
    "\n",
    "                batch_counter += 1\n",
    "\n",
    "                _, logits_1 = sess.run([optimizer, logits],\n",
    "                                   {inputs: batch_x,\n",
    "                                    labels: batch_y,\n",
    "                                    weights: batch_w,\n",
    "                                    keep_prob: keep_prob_})\n",
    "                \n",
    "                print(logits_1)\n",
    "\n",
    "                if batch_counter % display_step == 0 and batch_i > 0:\n",
    "                    \n",
    "                    print(batch_x, batch_y, batch_w)\n",
    "\n",
    "                    cost_train = sess.run(cost,{inputs: batch_x,\n",
    "                                                labels: batch_y,\n",
    "                                                weights: batch_w,\n",
    "                                                keep_prob: 1.0})\n",
    "                    print(cost_train)\n",
    "\n",
    "                    cost_valid_a = []\n",
    "\n",
    "                    for iii, (valid_batch_x,\n",
    "                              valid_batch_y,\n",
    "                              valid_batch_w) in enumerate(get_batches(x_valid,\n",
    "                                                                      y_valid,\n",
    "                                                                      w_valid,\n",
    "                                                                      batch_size)):\n",
    "\n",
    "                        cost_valid_i = sess.run(cost,{inputs: valid_batch_x,\n",
    "                                                      labels: valid_batch_y,\n",
    "                                                      weights: valid_batch_w,\n",
    "                                                      keep_prob: 1.0})\n",
    "\n",
    "                        cost_valid_a.append(cost_valid_i)\n",
    "\n",
    "                    cost_valid = sum(cost_valid_a) / len(cost_valid_a)\n",
    "\n",
    "                    total_time = time.time() - start_time\n",
    "\n",
    "                    print('CV: {} |'.format(cv_counter),\n",
    "                          'Epoch: {}/{} |'.format(epoch_i + 1, epochs),\n",
    "                          'Batch: {} |'.format(batch_counter),\n",
    "                          'Time: {:>3.2f}s |'.format(total_time),\n",
    "                          'Train_Loss: {:>.8f} |'.format(cost_train),\n",
    "                          'Valid_Loss: {:>.8f}'.format(cost_valid))\n",
    "\n",
    "                    print(sess.run(logits, {inputs: x_test_d, keep_prob: 1.0, is_train: False}))\n",
    "\n",
    "        # Prediction\n",
    "        print('Predicting...')\n",
    "\n",
    "        logits_ = sess.run(logits, {inputs: x_test,\n",
    "                                    keep_prob: 1.0,\n",
    "                                    is_train: False})\n",
    "\n",
    "        logits_ = logits_.flatten()\n",
    "\n",
    "        prob_test = 1.0 / (1.0 + np.exp(-logits_))\n",
    "\n",
    "        prob_total.append(list(prob_test))\n",
    "\n",
    "        utils.save_pred_to_csv(pred_path + 'dnn_cv_{}_'.format(cv_counter), id_test, prob_test)\n",
    "\n",
    "    # Final Result\n",
    "    print('======================================================================================================')\n",
    "    print('Calculating final result...')\n",
    "\n",
    "    prob_mean = np.mean(np.array(prob_total), axis=0)\n",
    "\n",
    "    utils.save_pred_to_csv(pred_path + 'dnn_', id_test, prob_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [[0.8, 0.2], \n",
    "     [0.3, 0.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(a)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
